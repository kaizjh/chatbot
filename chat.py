from file import model_inference
import gradio as gr


EXAMPLES = [
    [
        {
            "text": "ä½ å¥½",
        }
    ],
    [
        {
            "text": "è‡ªæˆ‘ä»‹ç»ä¸€ä¸‹å§",
        }
    ],
    [
        {
            "text": "lcmæ˜¯ä»€ä¹ˆï¼Ÿ",
        }
    ],
    [
        {
            "text": "lcmæ˜¯ä»€ä¹ˆï¼Ÿ",
            "files": ["example_files/lcm.pdf"]
        }
    ],
    [
        {
            "text": "åˆ†æä¸€ä¸‹è¿™å¼ å›¾ç‰‡",
            "files": ["example_files/1.jpg"]
        }
    ],
    [
        {
            "text": "è§†é¢‘ä¸­çš„äººç‰©æ˜¯è°ï¼Ÿ",
            "files": ["example_files/1.gif"]
        }
    ],
    [
        {
            "text": "è¿™æ˜¯æ¸¸æˆè¿˜æ˜¯ç°å®ï¼Ÿ",
            "files": ["example_files/1.mp4"]
        }
    ],

]


# Main application block
with gr.Blocks() as demo:
    gr.Markdown("# ğŸš€ å¤šæ¨¡æ€æ™ºèƒ½èŠå¤©æœºå™¨äºº", elem_classes="main-header")
    gr.ChatInterface(
            description="éšæ—¶æ¬¢è¿æé—®ï¼Œè¿˜å¯ä»¥ä¸Šä¼ å›¾ç‰‡ã€è§†é¢‘æé—®å“¦ï¼",
            examples=EXAMPLES,
            fill_height=False,
            fn=model_inference,
            multimodal=True,
            submit_btn="Submit",
            stop_btn="Stop", 
            # theme="soft",
            # title="Kai",
            type="messages",
    )

if __name__ == "__main__":
    demo.launch()
    